04/22 04:27:08 PM: Printing arguments : Namespace(checkpoint='best_model_dir_1234/unilstm_best.pth', senteval_vocab=True, encoder='unilstm', snli=True, senteval=True, seed=1111, num_workers=4, batch_size=64, sent_eval_path='./SentEval/data', tokenize=False)
04/22 04:27:08 PM: Setting seed...
04/22 04:27:08 PM: Vocab already exists. Loading from disk...
04/22 04:27:15 PM: Loading the model checkpoint from best_model_dir_1234/unilstm_best.pth
04/22 04:27:16 PM: Loading the model checkpoint trained in SNLI dataset
04/22 04:27:16 PM: Evaluating the model on SNLI dataset
04/22 04:27:16 PM: Batch: 1/154, Loss: 0.5751, Acc: 79.6875
04/22 04:27:17 PM: Batch: 11/154, Loss: 0.5387, Acc: 78.1250
04/22 04:27:17 PM: Batch: 21/154, Loss: 0.7191, Acc: 76.5625
04/22 04:27:17 PM: Batch: 31/154, Loss: 0.3842, Acc: 85.9375
04/22 04:27:17 PM: Batch: 41/154, Loss: 0.4844, Acc: 82.8125
04/22 04:27:17 PM: Batch: 51/154, Loss: 0.5593, Acc: 79.6875
04/22 04:27:17 PM: Batch: 61/154, Loss: 0.6732, Acc: 76.5625
04/22 04:27:17 PM: Batch: 71/154, Loss: 0.9029, Acc: 67.1875
04/22 04:27:17 PM: Batch: 81/154, Loss: 0.5898, Acc: 79.6875
04/22 04:27:17 PM: Batch: 91/154, Loss: 0.8110, Acc: 76.5625
04/22 04:27:17 PM: Batch: 101/154, Loss: 0.5516, Acc: 81.2500
04/22 04:27:17 PM: Batch: 111/154, Loss: 0.3184, Acc: 89.0625
04/22 04:27:17 PM: Batch: 121/154, Loss: 0.5422, Acc: 79.6875
04/22 04:27:17 PM: Batch: 131/154, Loss: 0.5606, Acc: 79.6875
04/22 04:27:17 PM: Batch: 141/154, Loss: 0.4469, Acc: 81.2500
04/22 04:27:17 PM: Batch: 151/154, Loss: 0.8925, Acc: 75.0000
04/22 04:27:18 PM: Batch: 1/154, Loss: 0.5224, Acc: 82.8125
04/22 04:27:18 PM: Batch: 11/154, Loss: 0.6578, Acc: 84.3750
04/22 04:27:18 PM: Batch: 21/154, Loss: 0.4602, Acc: 84.3750
04/22 04:27:18 PM: Batch: 31/154, Loss: 0.5479, Acc: 82.8125
04/22 04:27:18 PM: Batch: 41/154, Loss: 0.5924, Acc: 82.8125
04/22 04:27:18 PM: Batch: 51/154, Loss: 0.7840, Acc: 76.5625
04/22 04:27:18 PM: Batch: 61/154, Loss: 0.4788, Acc: 87.5000
04/22 04:27:18 PM: Batch: 71/154, Loss: 0.7821, Acc: 78.1250
04/22 04:27:18 PM: Batch: 81/154, Loss: 0.8442, Acc: 71.8750
04/22 04:27:18 PM: Batch: 91/154, Loss: 0.5962, Acc: 81.2500
04/22 04:27:18 PM: Batch: 101/154, Loss: 0.6049, Acc: 85.9375
04/22 04:27:18 PM: Batch: 111/154, Loss: 0.5112, Acc: 81.2500
04/22 04:27:19 PM: Batch: 121/154, Loss: 0.5359, Acc: 82.8125
04/22 04:27:19 PM: Batch: 131/154, Loss: 0.4998, Acc: 81.2500
04/22 04:27:19 PM: Batch: 141/154, Loss: 0.5740, Acc: 78.1250
04/22 04:27:19 PM: Batch: 151/154, Loss: 0.4813, Acc: 84.3750
04/22 04:27:19 PM: Validation loss: 0.5923, Validation accuracy: 80.4003
04/22 04:27:19 PM: Test loss: 0.5945, Test accuracy: 79.9165
04/22 04:27:19 PM: Evaluating the model on SentEval tasks
04/22 04:27:19 PM: Building vocabulary for task MR...
04/22 04:27:19 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:27:21 PM: Building unique tokens of vocab based on MR..
04/22 04:27:21 PM: Building w2i and aligned embeddings for task MR
04/22 04:27:21 PM: Generating sentence embeddings
04/22 04:27:22 PM: Generated sentence embeddings
04/22 04:27:22 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
04/22 04:28:29 PM: Best param found at split 1: l2reg = 1e-05                 with score 75.1
04/22 04:29:29 PM: Best param found at split 2: l2reg = 0.001                 with score 74.45
04/22 04:30:32 PM: Best param found at split 3: l2reg = 1e-05                 with score 74.79
04/22 04:31:33 PM: Best param found at split 4: l2reg = 0.0001                 with score 74.7
04/22 04:32:33 PM: Best param found at split 5: l2reg = 1e-05                 with score 75.02
04/22 04:32:37 PM: Building vocabulary for task CR...
04/22 04:32:37 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:32:39 PM: Building unique tokens of vocab based on CR..
04/22 04:32:39 PM: Building w2i and aligned embeddings for task CR
04/22 04:32:39 PM: Generating sentence embeddings
04/22 04:32:39 PM: Generated sentence embeddings
04/22 04:32:39 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
04/22 04:32:59 PM: Best param found at split 1: l2reg = 0.001                 with score 78.64
04/22 04:33:20 PM: Best param found at split 2: l2reg = 0.001                 with score 78.54
04/22 04:33:40 PM: Best param found at split 3: l2reg = 1e-05                 with score 78.15
04/22 04:34:00 PM: Best param found at split 4: l2reg = 1e-05                 with score 78.77
04/22 04:34:21 PM: Best param found at split 5: l2reg = 0.001                 with score 78.51
04/22 04:34:22 PM: Building vocabulary for task MPQA...
04/22 04:34:22 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:34:24 PM: Building unique tokens of vocab based on MPQA..
04/22 04:34:24 PM: Building w2i and aligned embeddings for task MPQA
04/22 04:34:24 PM: Generating sentence embeddings
04/22 04:34:24 PM: Generated sentence embeddings
04/22 04:34:24 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
04/22 04:35:18 PM: Best param found at split 1: l2reg = 0.0001                 with score 88.38
04/22 04:36:18 PM: Best param found at split 2: l2reg = 0.001                 with score 87.77
04/22 04:37:19 PM: Best param found at split 3: l2reg = 1e-05                 with score 88.01
04/22 04:38:21 PM: Best param found at split 4: l2reg = 0.0001                 with score 88.31
04/22 04:39:28 PM: Best param found at split 5: l2reg = 1e-05                 with score 88.19
04/22 04:39:32 PM: Building vocabulary for task SUBJ...
04/22 04:39:32 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:39:34 PM: Building unique tokens of vocab based on SUBJ..
04/22 04:39:34 PM: Building w2i and aligned embeddings for task SUBJ
04/22 04:39:34 PM: Generating sentence embeddings
04/22 04:39:35 PM: Generated sentence embeddings
04/22 04:39:35 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
04/22 04:40:41 PM: Best param found at split 1: l2reg = 1e-05                 with score 87.49
04/22 04:41:41 PM: Best param found at split 2: l2reg = 0.0001                 with score 87.63
04/22 04:42:50 PM: Best param found at split 3: l2reg = 1e-05                 with score 87.51
04/22 04:43:50 PM: Best param found at split 4: l2reg = 1e-05                 with score 87.55
04/22 04:44:59 PM: Best param found at split 5: l2reg = 0.0001                 with score 87.41
04/22 04:45:03 PM: Building vocabulary for task SST2...
04/22 04:45:03 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:45:05 PM: Building unique tokens of vocab based on SST2..
04/22 04:45:05 PM: Building w2i and aligned embeddings for task SST2
04/22 04:45:05 PM: Computing embedding for train
04/22 04:45:08 PM: Computed train embeddings
04/22 04:45:08 PM: Computing embedding for dev
04/22 04:45:08 PM: Computed dev embeddings
04/22 04:45:08 PM: Computing embedding for test
04/22 04:45:08 PM: Computed test embeddings
04/22 04:45:08 PM: Training pytorch-MLP-nhid0-adam-bs64 with standard validation..
04/22 04:46:37 PM: [('reg:1e-05', 79.24), ('reg:0.0001', 79.82), ('reg:0.001', 79.24), ('reg:0.01', 79.01)]
04/22 04:46:37 PM: Validation : best param found is reg = 0.0001 with score             79.82
04/22 04:46:37 PM: Evaluating...
04/22 04:46:59 PM: ***** Transfer task : TREC *****


04/22 04:46:59 PM: Building vocabulary for task TREC...
04/22 04:46:59 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:47:01 PM: Building unique tokens of vocab based on TREC..
04/22 04:47:01 PM: Building w2i and aligned embeddings for task TREC
04/22 04:47:01 PM: Computed train embeddings
04/22 04:47:01 PM: Computed test embeddings
04/22 04:47:01 PM: Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation
04/22 04:47:55 PM: [('reg:1e-05', 68.05), ('reg:0.0001', 68.01), ('reg:0.001', 66.97), ('reg:0.01', 61.89)]
04/22 04:47:55 PM: Cross-validation : best param found is reg = 1e-05             with score 68.05
04/22 04:47:55 PM: Evaluating...
04/22 04:47:59 PM: ***** Transfer task : MRPC *****


04/22 04:47:59 PM: Building vocabulary for task MRPC...
04/22 04:47:59 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:48:01 PM: Building unique tokens of vocab based on MRPC..
04/22 04:48:01 PM: Building w2i and aligned embeddings for task MRPC
04/22 04:48:01 PM: Computing embedding for train
04/22 04:48:02 PM: Computed train embeddings
04/22 04:48:02 PM: Computing embedding for test
04/22 04:48:02 PM: Computed test embeddings
04/22 04:48:02 PM: Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation
04/22 04:48:33 PM: [('reg:1e-05', 73.92), ('reg:0.0001', 73.82), ('reg:0.001', 73.21), ('reg:0.01', 71.64)]
04/22 04:48:33 PM: Cross-validation : best param found is reg = 1e-05             with score 73.92
04/22 04:48:33 PM: Evaluating...
04/22 04:48:35 PM: Building vocabulary for task SICKEntailment...
04/22 04:48:35 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:48:37 PM: Building unique tokens of vocab based on SICKEntailment..
04/22 04:48:37 PM: Building w2i and aligned embeddings for task SICKEntailment
04/22 04:48:37 PM: Computing embedding for train
04/22 04:48:37 PM: Computed train embeddings
04/22 04:48:37 PM: Computing embedding for dev
04/22 04:48:37 PM: Computed dev embeddings
04/22 04:48:37 PM: Computing embedding for test
04/22 04:48:37 PM: Computed test embeddings
04/22 04:48:38 PM: Training pytorch-MLP-nhid0-adam-bs64 with standard validation..
04/22 04:48:45 PM: [('reg:1e-05', 83.8), ('reg:0.0001', 83.8), ('reg:0.001', 83.6), ('reg:0.01', 83.0)]
04/22 04:48:45 PM: Validation : best param found is reg = 1e-05 with score             83.8
04/22 04:48:45 PM: Evaluating...
04/22 04:48:46 PM: Building vocabulary for task STS14...
04/22 04:48:46 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt
04/22 04:48:49 PM: Building unique tokens of vocab based on STS14..
04/22 04:48:49 PM: Building w2i and aligned embeddings for task STS14
04/22 04:48:49 PM: Results on SentEval tasks: {'MR': {'devacc': 74.81, 'acc': 74.49, 'ndev': 10662, 'ntest': 10662}, 'CR': {'devacc': 78.52, 'acc': 77.19, 'ndev': 3775, 'ntest': 3775}, 'MPQA': {'devacc': 88.13, 'acc': 87.8, 'ndev': 10606, 'ntest': 10606}, 'SUBJ': {'devacc': 87.52, 'acc': 87.12, 'ndev': 10000, 'ntest': 10000}, 'SST2': {'devacc': 79.82, 'acc': 77.92, 'ndev': 872, 'ntest': 1821}, 'TREC': {'devacc': 68.05, 'acc': 79.4, 'ndev': 5452, 'ntest': 500}, 'MRPC': {'devacc': 73.92, 'acc': 72.81, 'f1': 81.2, 'ndev': 4076, 'ntest': 1725}, 'SICKEntailment': {'devacc': 83.8, 'acc': 83.6, 'ndev': 500, 'ntest': 4927}, 'STS14': {'deft-forum': {'pearson': PearsonRResult(statistic=0.4147567137193578, pvalue=3.8887972298217205e-20), 'spearman': SignificanceResult(statistic=0.43373324952382947, pvalue=4.575049299954298e-22), 'nsamples': 450}, 'deft-news': {'pearson': PearsonRResult(statistic=0.604025683912967, pvalue=3.2344412488435363e-31), 'spearman': SignificanceResult(statistic=0.5679944937263941, pvalue=5.027747787506259e-27), 'nsamples': 300}, 'headlines': {'pearson': PearsonRResult(statistic=0.5320281549926553, pvalue=4.890973984038309e-56), 'spearman': SignificanceResult(statistic=0.4858665535986944, pvalue=1.0946906461756806e-45), 'nsamples': 750}, 'images': {'pearson': PearsonRResult(statistic=0.8003981743940712, pvalue=2.140834593523644e-168), 'spearman': SignificanceResult(statistic=0.7548516234667298, pvalue=3.792370388640789e-139), 'nsamples': 750}, 'OnWN': {'pearson': PearsonRResult(statistic=0.6819911368829885, pvalue=1.0016978793490421e-103), 'spearman': SignificanceResult(statistic=0.7132931486737693, pvalue=1.3992814152691205e-117), 'nsamples': 750}, 'tweet-news': {'pearson': PearsonRResult(statistic=0.5681066515323037, pvalue=2.5733424890064873e-65), 'spearman': SignificanceResult(statistic=0.5152060332978783, pvalue=4.4267273180618536e-52), 'nsamples': 750}, 'all': {'pearson': {'mean': 0.6002177525723905, 'wmean': 0.6145976839197641}, 'spearman': {'mean': 0.578490850381216, 'wmean': 0.5913310212483854}}}}
04/22 04:48:49 PM: --------------------------------
04/22 04:48:49 PM: Results with tokenization: False on SenteEval
04/22 04:48:49 PM: Results with building new Vocab. based on SentEval
04/22 04:48:49 PM: Seed used: 1111
04/22 04:48:49 PM: Macro accuracy: 79.3212
04/22 04:48:49 PM: Micro score: 80.2680
04/22 04:48:49 PM: --------------------------------

JOB STATISTICS
==============
Job ID: 6012474
Cluster: snellius
User/Group: scur1398/scur1398
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:37:12 core-walltime
Job Wall-clock time: 00:22:04
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
