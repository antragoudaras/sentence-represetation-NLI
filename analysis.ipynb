{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning sentence representations from natural language iference data (SNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of all models on both SNLI and SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/baseline_best.pth\"\n",
    "encoder = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22 10:08:06 PM: Printing arguments : Namespace(checkpoint='best_model_dir_1234/baseline_best.pth', senteval_vocab=True, encoder='baseline', snli=True, senteval=True, seed=1111, num_workers=4, batch_size=64, sent_eval_path='./SentEval/data', tokenize=False)\n",
      "04/22 10:08:06 PM: Setting seed...\n",
      "04/22 10:08:06 PM: Vocab already exists. Loading from disk...\n",
      "04/22 10:08:15 PM: Loading the model checkpoint from best_model_dir_1234/baseline_best.pth\n",
      "04/22 10:08:15 PM: Loading the model checkpoint trained in SNLI dataset\n",
      "04/22 10:08:15 PM: Evaluating the model on SNLI dataset\n",
      "04/22 10:08:16 PM: Batch: 1/154, Loss: 0.7540, Acc: 64.0625\n",
      "04/22 10:08:16 PM: Batch: 11/154, Loss: 0.7281, Acc: 68.7500\n",
      "04/22 10:08:16 PM: Batch: 21/154, Loss: 0.8359, Acc: 56.2500\n",
      "04/22 10:08:16 PM: Batch: 31/154, Loss: 0.6027, Acc: 78.1250\n",
      "04/22 10:08:16 PM: Batch: 41/154, Loss: 0.7169, Acc: 73.4375\n",
      "04/22 10:08:16 PM: Batch: 51/154, Loss: 0.8181, Acc: 60.9375\n",
      "04/22 10:08:16 PM: Batch: 61/154, Loss: 0.8406, Acc: 56.2500\n",
      "04/22 10:08:16 PM: Batch: 71/154, Loss: 0.8812, Acc: 56.2500\n",
      "04/22 10:08:16 PM: Batch: 81/154, Loss: 0.8277, Acc: 68.7500\n",
      "04/22 10:08:16 PM: Batch: 91/154, Loss: 0.7731, Acc: 68.7500\n",
      "04/22 10:08:16 PM: Batch: 101/154, Loss: 0.7951, Acc: 68.7500\n",
      "04/22 10:08:16 PM: Batch: 111/154, Loss: 0.6731, Acc: 71.8750\n",
      "04/22 10:08:16 PM: Batch: 121/154, Loss: 0.7259, Acc: 68.7500\n",
      "04/22 10:08:16 PM: Batch: 131/154, Loss: 0.9434, Acc: 59.3750\n",
      "04/22 10:08:16 PM: Batch: 141/154, Loss: 0.7814, Acc: 67.1875\n",
      "04/22 10:08:16 PM: Batch: 151/154, Loss: 0.7647, Acc: 70.3125\n",
      "04/22 10:08:16 PM: Batch: 1/154, Loss: 0.7939, Acc: 64.0625\n",
      "04/22 10:08:16 PM: Batch: 11/154, Loss: 0.7908, Acc: 64.0625\n",
      "04/22 10:08:16 PM: Batch: 21/154, Loss: 0.7190, Acc: 76.5625\n",
      "04/22 10:08:16 PM: Batch: 31/154, Loss: 0.7624, Acc: 70.3125\n",
      "04/22 10:08:16 PM: Batch: 41/154, Loss: 0.7618, Acc: 60.9375\n",
      "04/22 10:08:16 PM: Batch: 51/154, Loss: 0.8279, Acc: 62.5000\n",
      "04/22 10:08:16 PM: Batch: 61/154, Loss: 0.7173, Acc: 65.6250\n",
      "04/22 10:08:16 PM: Batch: 71/154, Loss: 0.7320, Acc: 67.1875\n",
      "04/22 10:08:16 PM: Batch: 81/154, Loss: 0.8302, Acc: 64.0625\n",
      "04/22 10:08:16 PM: Batch: 91/154, Loss: 0.7427, Acc: 68.7500\n",
      "04/22 10:08:17 PM: Batch: 101/154, Loss: 0.8435, Acc: 65.6250\n",
      "04/22 10:08:17 PM: Batch: 111/154, Loss: 0.8206, Acc: 65.6250\n",
      "04/22 10:08:17 PM: Batch: 121/154, Loss: 0.7490, Acc: 67.1875\n",
      "04/22 10:08:17 PM: Batch: 131/154, Loss: 0.8047, Acc: 67.1875\n",
      "04/22 10:08:17 PM: Batch: 141/154, Loss: 0.8268, Acc: 67.1875\n",
      "04/22 10:08:17 PM: Batch: 151/154, Loss: 0.8763, Acc: 62.5000\n",
      "04/22 10:08:17 PM: Validation loss: 0.7840, Validation accuracy: 66.0536\n",
      "04/22 10:08:17 PM: Test loss: 0.7885, Test accuracy: 66.1950\n",
      "04/22 10:08:17 PM: Evaluating the model on SentEval tasks\n",
      "04/22 10:08:17 PM: Building vocabulary for task MR...\n",
      "04/22 10:08:17 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:08:20 PM: Building unique tokens of vocab based on MR..\n",
      "04/22 10:08:20 PM: Building w2i and aligned embeddings for task MR\n",
      "04/22 10:08:20 PM: Generating sentence embeddings\n",
      "04/22 10:08:20 PM: Generated sentence embeddings\n",
      "04/22 10:08:20 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation\n",
      "04/22 10:09:28 PM: Best param found at split 1: l2reg = 1e-05                 with score 77.73\n",
      "04/22 10:10:47 PM: Best param found at split 2: l2reg = 0.0001                 with score 77.91\n",
      "04/22 10:12:05 PM: Best param found at split 3: l2reg = 1e-05                 with score 77.47\n",
      "04/22 10:13:24 PM: Best param found at split 4: l2reg = 0.0001                 with score 77.69\n",
      "04/22 10:14:38 PM: Best param found at split 5: l2reg = 0.0001                 with score 77.67\n",
      "04/22 10:14:41 PM: Building vocabulary for task CR...\n",
      "04/22 10:14:41 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:14:43 PM: Building unique tokens of vocab based on CR..\n",
      "04/22 10:14:43 PM: Building w2i and aligned embeddings for task CR\n",
      "04/22 10:14:43 PM: Generating sentence embeddings\n",
      "04/22 10:14:43 PM: Generated sentence embeddings\n",
      "04/22 10:14:43 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation\n",
      "04/22 10:15:13 PM: Best param found at split 1: l2reg = 1e-05                 with score 79.57\n",
      "04/22 10:15:44 PM: Best param found at split 2: l2reg = 0.0001                 with score 79.6\n",
      "04/22 10:16:13 PM: Best param found at split 3: l2reg = 1e-05                 with score 79.07\n",
      "04/22 10:16:44 PM: Best param found at split 4: l2reg = 1e-05                 with score 79.24\n",
      "04/22 10:17:16 PM: Best param found at split 5: l2reg = 1e-05                 with score 79.93\n",
      "04/22 10:17:17 PM: Building vocabulary for task MPQA...\n",
      "04/22 10:17:17 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:17:19 PM: Building unique tokens of vocab based on MPQA..\n",
      "04/22 10:17:19 PM: Building w2i and aligned embeddings for task MPQA\n",
      "04/22 10:17:19 PM: Generating sentence embeddings\n",
      "04/22 10:17:19 PM: Generated sentence embeddings\n",
      "04/22 10:17:19 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation\n",
      "04/22 10:18:23 PM: Best param found at split 1: l2reg = 0.0001                 with score 88.15\n",
      "04/22 10:19:33 PM: Best param found at split 2: l2reg = 0.001                 with score 87.38\n",
      "04/22 10:20:42 PM: Best param found at split 3: l2reg = 0.0001                 with score 87.99\n",
      "04/22 10:21:53 PM: Best param found at split 4: l2reg = 1e-05                 with score 87.91\n",
      "04/22 10:23:08 PM: Best param found at split 5: l2reg = 1e-05                 with score 88.03\n",
      "04/22 10:23:11 PM: Building vocabulary for task SUBJ...\n",
      "04/22 10:23:11 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:23:14 PM: Building unique tokens of vocab based on SUBJ..\n",
      "04/22 10:23:14 PM: Building w2i and aligned embeddings for task SUBJ\n",
      "04/22 10:23:14 PM: Generating sentence embeddings\n",
      "04/22 10:23:14 PM: Generated sentence embeddings\n",
      "04/22 10:23:14 PM: Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation\n",
      "04/22 10:24:32 PM: Best param found at split 1: l2reg = 0.0001                 with score 91.34\n",
      "04/22 10:25:47 PM: Best param found at split 2: l2reg = 0.0001                 with score 91.36\n",
      "04/22 10:27:07 PM: Best param found at split 3: l2reg = 1e-05                 with score 91.79\n",
      "04/22 10:28:27 PM: Best param found at split 4: l2reg = 1e-05                 with score 91.66\n",
      "04/22 10:29:47 PM: Best param found at split 5: l2reg = 1e-05                 with score 91.38\n",
      "04/22 10:29:51 PM: Building vocabulary for task SST2...\n",
      "04/22 10:29:51 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:29:54 PM: Building unique tokens of vocab based on SST2..\n",
      "04/22 10:29:54 PM: Building w2i and aligned embeddings for task SST2\n",
      "04/22 10:29:54 PM: Computing embedding for train\n",
      "04/22 10:29:55 PM: Computed train embeddings\n",
      "04/22 10:29:55 PM: Computing embedding for dev\n",
      "04/22 10:29:55 PM: Computed dev embeddings\n",
      "04/22 10:29:55 PM: Computing embedding for test\n",
      "04/22 10:29:55 PM: Computed test embeddings\n",
      "04/22 10:29:55 PM: Training pytorch-MLP-nhid0-adam-bs64 with standard validation..\n",
      "04/22 10:31:35 PM: [('reg:1e-05', 79.13), ('reg:0.0001', 79.24), ('reg:0.001', 79.24), ('reg:0.01', 77.87)]\n",
      "04/22 10:31:35 PM: Validation : best param found is reg = 0.0001 with score             79.24\n",
      "04/22 10:31:35 PM: Evaluating...\n",
      "04/22 10:32:01 PM: ***** Transfer task : TREC *****\n",
      "\n",
      "\n",
      "04/22 10:32:01 PM: Building vocabulary for task TREC...\n",
      "04/22 10:32:01 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:32:03 PM: Building unique tokens of vocab based on TREC..\n",
      "04/22 10:32:03 PM: Building w2i and aligned embeddings for task TREC\n",
      "04/22 10:32:03 PM: Computed train embeddings\n",
      "04/22 10:32:03 PM: Computed test embeddings\n",
      "04/22 10:32:03 PM: Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation\n",
      "04/22 10:33:14 PM: [('reg:1e-05', 73.86), ('reg:0.0001', 73.68), ('reg:0.001', 72.96), ('reg:0.01', 65.65)]\n",
      "04/22 10:33:14 PM: Cross-validation : best param found is reg = 1e-05             with score 73.86\n",
      "04/22 10:33:14 PM: Evaluating...\n",
      "04/22 10:33:17 PM: ***** Transfer task : MRPC *****\n",
      "\n",
      "\n",
      "04/22 10:33:17 PM: Building vocabulary for task MRPC...\n",
      "04/22 10:33:17 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:33:19 PM: Building unique tokens of vocab based on MRPC..\n",
      "04/22 10:33:19 PM: Building w2i and aligned embeddings for task MRPC\n",
      "04/22 10:33:20 PM: Computing embedding for train\n",
      "04/22 10:33:20 PM: Computed train embeddings\n",
      "04/22 10:33:20 PM: Computing embedding for test\n",
      "04/22 10:33:20 PM: Computed test embeddings\n",
      "04/22 10:33:20 PM: Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation\n",
      "04/22 10:33:52 PM: [('reg:1e-05', 74.02), ('reg:0.0001', 73.87), ('reg:0.001', 73.21), ('reg:0.01', 71.74)]\n",
      "04/22 10:33:52 PM: Cross-validation : best param found is reg = 1e-05             with score 74.02\n",
      "04/22 10:33:52 PM: Evaluating...\n",
      "04/22 10:33:54 PM: Building vocabulary for task SICKEntailment...\n",
      "04/22 10:33:54 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:33:57 PM: Building unique tokens of vocab based on SICKEntailment..\n",
      "04/22 10:33:57 PM: Building w2i and aligned embeddings for task SICKEntailment\n",
      "04/22 10:33:57 PM: Computing embedding for train\n",
      "04/22 10:33:57 PM: Computed train embeddings\n",
      "04/22 10:33:57 PM: Computing embedding for dev\n",
      "04/22 10:33:57 PM: Computed dev embeddings\n",
      "04/22 10:33:57 PM: Computing embedding for test\n",
      "04/22 10:33:57 PM: Computed test embeddings\n",
      "04/22 10:33:57 PM: Training pytorch-MLP-nhid0-adam-bs64 with standard validation..\n",
      "04/22 10:34:09 PM: [('reg:1e-05', 81.0), ('reg:0.0001', 81.0), ('reg:0.001', 79.4), ('reg:0.01', 71.0)]\n",
      "04/22 10:34:09 PM: Validation : best param found is reg = 1e-05 with score             81.0\n",
      "04/22 10:34:09 PM: Evaluating...\n",
      "04/22 10:34:12 PM: Building vocabulary for task STS14...\n",
      "04/22 10:34:12 PM: Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n",
      "04/22 10:34:15 PM: Building unique tokens of vocab based on STS14..\n",
      "04/22 10:34:15 PM: Building w2i and aligned embeddings for task STS14\n",
      "04/22 10:34:15 PM: Results on SentEval tasks: {'MR': {'devacc': 77.69, 'acc': 77.33, 'ndev': 10662, 'ntest': 10662}, 'CR': {'devacc': 79.48, 'acc': 77.88, 'ndev': 3775, 'ntest': 3775}, 'MPQA': {'devacc': 87.89, 'acc': 87.71, 'ndev': 10606, 'ntest': 10606}, 'SUBJ': {'devacc': 91.51, 'acc': 91.4, 'ndev': 10000, 'ntest': 10000}, 'SST2': {'devacc': 79.24, 'acc': 80.29, 'ndev': 872, 'ntest': 1821}, 'TREC': {'devacc': 73.86, 'acc': 83.0, 'ndev': 5452, 'ntest': 500}, 'MRPC': {'devacc': 74.02, 'acc': 72.87, 'f1': 81.38, 'ndev': 4076, 'ntest': 1725}, 'SICKEntailment': {'devacc': 81.0, 'acc': 78.49, 'ndev': 500, 'ntest': 4927}, 'STS14': {'deft-forum': {'pearson': PearsonRResult(statistic=0.30015698920392164, pvalue=8.028873135607622e-11), 'spearman': SignificanceResult(statistic=0.34719792930633214, pvalue=3.407223149511437e-14), 'nsamples': 450}, 'deft-news': {'pearson': PearsonRResult(statistic=0.6494705707929106, pvalue=2.501700382866815e-37), 'spearman': SignificanceResult(statistic=0.6456219780351091, pvalue=9.041047812255562e-37), 'nsamples': 300}, 'headlines': {'pearson': PearsonRResult(statistic=0.586720905706843, pvalue=1.437358864145757e-70), 'spearman': SignificanceResult(statistic=0.5510040795093948, pvalue=8.917978464050785e-61), 'nsamples': 750}, 'images': {'pearson': PearsonRResult(statistic=0.6240477685364034, pvalue=3.406366662482351e-82), 'spearman': SignificanceResult(statistic=0.6127334964976213, pvalue=1.662435217385402e-78), 'nsamples': 750}, 'OnWN': {'pearson': PearsonRResult(statistic=0.577094279673974, pvalue=8.24707804240312e-68), 'spearman': SignificanceResult(statistic=0.6434659871555309, pvalue=6.851316923329252e-89), 'nsamples': 750}, 'tweet-news': {'pearson': PearsonRResult(statistic=0.5384018263562398, pvalue=1.3526868744507565e-57), 'spearman': SignificanceResult(statistic=0.5379424869568135, pvalue=1.756348757209049e-57), 'nsamples': 750}, 'all': {'pearson': {'mean': 0.5459820567117154, 'wmean': 0.5532294404225955}, 'spearman': {'mean': 0.5563276595768003, 'wmean': 0.5623427197834406}}}}\n",
      "04/22 10:34:15 PM: --------------------------------\n",
      "04/22 10:34:15 PM: Results with tokenization: False on SenteEval\n",
      "04/22 10:34:15 PM: Results with building new Vocab. based on SentEval\n",
      "04/22 10:34:15 PM: Seed used: 1111\n",
      "04/22 10:34:15 PM: Macro accuracy: 80.5863\n",
      "04/22 10:34:15 PM: Micro score: 82.4852\n",
      "04/22 10:34:15 PM: --------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python eval.py $checkpoint --senteval-vocab --encoder $encoder --snli --senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/unilstm_best.pth\"\n",
    "encoder = \"unilstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py $checkpoint --senteval-vocab --encoder $encoder --snli --senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/bilstm_best.pth\"\n",
    "encoder = \"bilstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py $checkpoint --senteval-vocab --encoder $encoder --snli --senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/bilstm_best.pth\"\n",
    "encoder = \"bilstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py $checkpoint --senteval-vocab --encoder $encoder --snli --senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/bilstm-max_best.pth\"\n",
    "encoder = \"bilstm-max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py $checkpoint --senteval-vocab --encoder $encoder --snli --senteval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of sentence encoder architectures on SNLI and (aggregated) SentEval tasks (reported with macro and micro accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table demonstartes the results of the models on the SNLI dev/validation and test sets, and the micro and macro averaged results on the SentEval tasks (computed from 'devacc').\n",
    "\n",
    "| **Model** | **SNLI Dev** | **SNLI Test** | **Micro** | **Macro** |\n",
    "|---|---|---|---|---|\n",
    "| Baseline | 66.0536% | 66.1950% | 82.4852% | 80.5863% |\n",
    "| LSTM | 80.4003% | 79.9165% | 80.2680% | 79.3212% |\n",
    "| BiLSTM-Concat | 79.9431% |79.7638% | 83.0806% | 82.0075% |\n",
    "| BiLSTM-Max | 84.2105% | 84.0798% | 84.5913% | 83.4000% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Results\n",
    "\n",
    "### Which model is Better?\n",
    "### Model performance\n",
    "\n",
    "Using the BiLSTM encoder with max-pooling resulted in the best-performing model across both SNLI and SentEval tasks, as anticipated. The latter can be credited to the architecture of the model. A bidirectional LSTM can capture information from both preceding and succeeding contexts, enhancing its capability to learn richer contextual sentence representations. The max pooling mechanism enables the model to prioritize salient features in an input sequence, boosting its resilience against sentence length and structure variations. Contrastively, the baseline model solely relies on averaging word embeddings, demonstrating inferior performance compared to BiLSTM and BiLSTM (max). Finally, the unidirectional LSTM performs similarly to the BILSTM-Concat, but its simplicity limits the model in the transfer tasks benchmark (SNLI). The latter can be attributed to the fact that the model learns more simplified contextualized representation due to the single-direction mechanism.\n",
    "### Failures\n",
    "\n",
    "Whenever a deeper understanding of the language is required, all models fail (see next section on predicting entailment on tricky premises and hypothesis). For instance, negation, complex sentence structure, and dependencies (e.g., long-range coreference) create model failures. The baseline model will have the most challenging time in such cases, as it relies exclusively on the average word embeddings that lack any information of context and word order. \n",
    "The unidirectional LSTM is expected to struggle when capturing dependencies that require considering the context from both directions is essential.\n",
    "Finally, BiLSTM-Concat and BiLSTM-Max models leverage bi-directionality and are the most robust methods, but they still need improvement. Long-range dependencies and several semantic relationships between premises and hypotheses requiring intricate handling can confuse the model.\n",
    "\n",
    "### Analysis of sentence embeddings\n",
    "\n",
    "All models learn sentence embeddings with a fixed dimensionality designed to capture the meaning and structure of a sentence. The baseline model captures the average of word meanings, thereby losing information about word order and context. The LSTM, BiLSTM, and BiLSTM (max) models are better at capturing the sequential character of sentences, the context in which words appear, and some word order. However, even the most complicated BiLSTM models have some information loss. For instance, they struggle to capture the intricacies of specific syntactic or semantic links (as seen in the section below on tricky entailment prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the BILSTM model and load the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"best_model_dir_1234/bilstm-max_best.pth\"\n",
    "encoder = \"bilstm-max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_1 = \"Two men sitting in the sun\"\n",
    "hypothesis_1 = \"Nobody is sitting in the shade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22 09:20:35 PM: Printing arguments : Namespace(checkpoint='best_model_dir_1234/bilstm-max_best.pth', encoder='bilstm-max', seed=1234, premise='Two men sitting in the sun', hypothesis='Nobody is sitting in the shade')\n",
      "04/22 09:20:35 PM: Setting seed...\n",
      "04/22 09:20:35 PM: Vocab already exists. Loading from disk...\n",
      "04/22 09:20:43 PM: Loading the model checkpoint from best_model_dir_1234/bilstm-max_best.pth\n",
      "04/22 09:20:44 PM: Loading the model checkpoint trained in SNLI dataset\n",
      "04/22 09:20:44 PM: Premise: Two men sitting in the sun\n",
      "04/22 09:20:44 PM: Hypothesis: Nobody is sitting in the shade\n",
      "04/22 09:20:44 PM: Entailment prediction: Contradiction\n"
     ]
    }
   ],
   "source": [
    "! python predict.py $checkpoint --encoder $encoder --premise \"$premise_1\" --hypothesis \"$hypothesis_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_2 = \"A man is walking a dog\"\n",
    "hypothesis_2 = \"No cat is outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22 09:20:48 PM: Printing arguments : Namespace(checkpoint='best_model_dir_1234/bilstm-max_best.pth', encoder='bilstm-max', seed=1234, premise='A man is walking a dog', hypothesis='No cat is outside')\n",
      "04/22 09:20:48 PM: Setting seed...\n",
      "04/22 09:20:48 PM: Vocab already exists. Loading from disk...\n",
      "04/22 09:20:57 PM: Loading the model checkpoint from best_model_dir_1234/bilstm-max_best.pth\n",
      "04/22 09:20:57 PM: Loading the model checkpoint trained in SNLI dataset\n",
      "04/22 09:20:58 PM: Premise: A man is walking a dog\n",
      "04/22 09:20:58 PM: Hypothesis: No cat is outside\n",
      "04/22 09:20:58 PM: Entailment prediction: Contradiction\n"
     ]
    }
   ],
   "source": [
    "! python predict.py $checkpoint --encoder $encoder --premise \"$premise_2\" --hypothesis \"$hypothesis_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One probable explanation for not capturing the correct entailment label is the presence of negations in the hypotheses, which may cause the model to focus on the premise's opposite meaning. The models may be more sensitive to negation words like \"nobody\" and \"no\" in the hypothesis, causing them to believe a contradiction element exists. Furthermore, the model struggles to recognize the connection between various entities in the sentences, such as \"men\" and \"nobody\" or \"dog\" and \"cat.\" This difficulty in capturing semantic relationships between items may cause the model to inaccurately judge the relationship between the premise and the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research Question\n",
    "#### How does the size of the sentences (premise ad hypothesis affects the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22 09:21:52 PM: Printing arguments : Namespace(checkpoint='best_model_dir_1234/bilstm-max_best.pth', encoder='bilstm-max', seed=1234, num_workers=4, batch_size=64, quartile_list=[0.1, 0.9])\n",
      "04/22 09:21:52 PM: Setting seed...\n",
      "04/22 09:21:52 PM: Vocab already exists. Loading from disk...\n",
      "04/22 09:22:01 PM: Loading the model checkpoint from best_model_dir_1234/bilstm-max_best.pth\n",
      "04/22 09:22:02 PM: Loading the model checkpoint trained in SNLI dataset\n",
      "Map: 100%|████████████████████████| 9824/9824 [00:00<00:00, 13293.10 examples/s]\n",
      "Filter: 100%|█████████████████████| 9824/9824 [00:00<00:00, 38436.60 examples/s]\n",
      "Filter: 100%|█████████████████████| 9824/9824 [00:00<00:00, 38473.92 examples/s]\n",
      "Filter: 100%|█████████████████████| 9824/9824 [00:00<00:00, 38915.85 examples/s]\n",
      "04/22 09:22:04 PM: Shortest dataset size: 822\n",
      "04/22 09:22:04 PM: Middle dataset size: 7897\n",
      "04/22 09:22:04 PM: Longest dataset size: 1105\n",
      "04/22 09:22:04 PM: average sentence length (sum of premise + hypothesis) of the dataset\n",
      "04/22 09:22:04 PM: Quartile 0: 12.77\n",
      "04/22 09:22:04 PM: Quartile 1: 22.60\n",
      "04/22 09:22:04 PM: Quartile 2: 39.17\n",
      "04/22 09:22:04 PM: Evaluating the model on each quartile dataset\n",
      "04/22 09:22:04 PM: Running evaluation on small dataset\n",
      "04/22 09:22:05 PM: Batch: 1/13, Loss: 0.7967, Acc: 81.2500\n",
      "04/22 09:22:05 PM: Batch: 11/13, Loss: 0.4161, Acc: 84.3750\n",
      "04/22 09:22:05 PM: -----------------------------------\n",
      "04/22 09:22:05 PM: Test Accuracy: 84.4282 on small dataset\n",
      "04/22 09:22:05 PM: -----------------------------------\n",
      "04/22 09:22:05 PM: Running evaluation on medium dataset\n",
      "04/22 09:22:05 PM: Batch: 1/124, Loss: 0.5188, Acc: 78.1250\n",
      "04/22 09:22:06 PM: Batch: 11/124, Loss: 0.7210, Acc: 81.2500\n",
      "04/22 09:22:06 PM: Batch: 21/124, Loss: 0.3716, Acc: 85.9375\n",
      "04/22 09:22:06 PM: Batch: 31/124, Loss: 0.3514, Acc: 85.9375\n",
      "04/22 09:22:06 PM: Batch: 41/124, Loss: 0.5167, Acc: 81.2500\n",
      "04/22 09:22:06 PM: Batch: 51/124, Loss: 0.3553, Acc: 89.0625\n",
      "04/22 09:22:06 PM: Batch: 61/124, Loss: 0.4816, Acc: 84.3750\n",
      "04/22 09:22:06 PM: Batch: 71/124, Loss: 0.6860, Acc: 82.8125\n",
      "04/22 09:22:06 PM: Batch: 81/124, Loss: 0.4482, Acc: 82.8125\n",
      "04/22 09:22:06 PM: Batch: 91/124, Loss: 0.3295, Acc: 90.6250\n",
      "04/22 09:22:06 PM: Batch: 101/124, Loss: 0.2998, Acc: 92.1875\n",
      "04/22 09:22:06 PM: Batch: 111/124, Loss: 0.4055, Acc: 84.3750\n",
      "04/22 09:22:06 PM: Batch: 121/124, Loss: 0.2877, Acc: 84.3750\n",
      "04/22 09:22:07 PM: -----------------------------------\n",
      "04/22 09:22:07 PM: Test Accuracy: 84.4118 on medium dataset\n",
      "04/22 09:22:07 PM: -----------------------------------\n",
      "04/22 09:22:07 PM: Running evaluation on large dataset\n",
      "04/22 09:22:07 PM: Batch: 1/18, Loss: 0.3628, Acc: 85.9375\n",
      "04/22 09:22:07 PM: Batch: 11/18, Loss: 0.3892, Acc: 84.3750\n",
      "04/22 09:22:07 PM: -----------------------------------\n",
      "04/22 09:22:07 PM: Test Accuracy: 81.4480 on large dataset\n",
      "04/22 09:22:07 PM: -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "! python eval_dataset_quartiles.py $checkpoint --encoder $encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this additional research question, we opt to use the BiLSTM-Max encoder as it is the prevailing model for the SNLI and SentEval tasks.\n",
    "The BiLSTM-Max model tends to perform better on shorter sentences, achieving an accuracy of 84.4282% on the short dataset with an average sentence length of 12.77. The model's performance gradually decreases as the sentence length increases. The accuracy of the medium dataset, with an average sentence length of 22.60, is 84.4118%. For the extended dataset that consists of 39.17 sentence length on average, we get the biggest diminish in accuracy, reaching 81.4480%. Our implementation uses quartiles (from Numpy) to create the dataset with smaller and larger average sentence sizes.\n",
    "\n",
    "These findings indicate that the BiLSTM (max) encoder is better at encoding shorter sentences than longer ones, which is unsurprising. As sentences grow in length, the model needs help to capture all of the necessary information and word associations. Longer phrases are more likely to cause the model to lose important information due to the inherent limits of LSTMs in dealing with long-range dependencies.\n",
    "Our results indicate that the model's capacity to handle extended sentences could be improved. Possible alternatives include adopting more complex models, such as Transformer-based model architectures, for a more rich contextualized representation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atcs-pr-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
